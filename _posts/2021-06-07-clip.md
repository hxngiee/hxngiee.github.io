---
layout: post
title: Learning Transferable Visual Models From Natural Language Supervision - 작성중
subtitle: Impressive zero shot performance for distribution shift and domain generalization
# thumbnail-img: /assets/img/pr_pono.png 
tags: [Paper Review]
comments: true
---

## Table of contents
- [Abstract](#abstract)

## Abstract
- introduce a concept of using zero shot in computer vision
- take nlp paradigm to computer vision 

## Method
### Contrastive pre-training
- Associated with they image/text pairs
- Image Part
  - data augmentation 
  - Image Encoder : ResNet and vision transformer
    - get certain representation at the output 
    - Linear Projection and finally inside contrastive embedding space
- Text Part
  - Text Encoder : Vaswani transformer
    - embed text sequence here 
    - Layer Normalization and use linear projection layer into the embedding space
$
\begin{eqnarray*}
        Cosine Similarity(I_i,T_j)=\left\{
                        \begin{array}{ll}
                            1, & \text{if~}i==j\\
                            0, & \text{otherwise}.
                        \end{array}
                  \right.
    \label{Example1}
\end{eqnarray*}
$

I1과 T1이 highest cosine similarity를 같도록 함. 그리고 나머지들과는 유사도가 zero가 되도록 함
마찬가지로 I1과 다른 T_i들과 zero cosine similarity를 갖도록 함
$Cosine Similarity(I_i,T_j) = 1$ if(i==j)
$Cosine Similarity(I_i,T_j) = 0$ if(i!=j)



## Problem Statement  
- Style Transfer  
    - 새롭게 합성될 영상의 feature map이 Content/Style Image로부터 나온 feature map과 비슷한 특성을 갖도록 근사

Q. 이 논문을 어떻게 이용할 수 있을까
Q. 참고하고 싶은 다른 레퍼런스
