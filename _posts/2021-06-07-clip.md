---
layout: post
title: Learning Transferable Visual Models From Natural Language Supervision - 작성중
subtitle: Impressive zero shot performance for distribution shift and domain generalization
# thumbnail-img: /assets/img/pr_pono.png 
tags: [Paper Review]
use_math: true
comments: true
---

## Table of contents
- [Abstract](#abstract)

## Abstract
- introduce a concept of using zero shot in computer vision
- take nlp paradigm to computer vision 

## Method
### Contrastive pre-training
- Associated with they image/text pairs
- Image Part
  - data augmentation 
  - Image Encoder : ResNet and vision transformer
    - get certain representation at the output 
    - Linear Projection and finally inside contrastive embedding space
- Text Part
  - Text Encoder : Vaswani transformer
    - embed text sequence here 
    - Layer Normalization and use linear projection layer into the embedding space  

  
$Cosine Similarity(I_i,T_i) =$
\begin{cases}
1,  & \text{if i==j} \\
0, & \text{otherwise}
\end{cases}  

Cosine Similarity(I_i,T_i) = \begin{cases} 1,  & \text{if i==j} \\ 0, & \text{otherwise} \end{cases} 




Q. 이 논문을 어떻게 이용할 수 있을까  
Q. 참고하고 싶은 다른 레퍼런스
